{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An initial training pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext dotenv\n",
    "%dotenv \n",
    "import os\n",
    "import sys\n",
    "sys.path.append(os.getenv('SRC_DIR'))\n",
    "import dask.dataframe as dd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from glob import glob\n",
    "ft_dir = os.getenv(\"FEATURES_DATA\")\n",
    "ft_glob = glob(ft_dir+'/*.parquet')\n",
    "df = dd.read_parquet(ft_glob).compute().reset_index().dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_file = os.path.join(\n",
    "    os.getenv(\"PRICE_CSV_DATA\"), \n",
    "    'symbols_valid_meta.csv'\n",
    ")\n",
    "cat_df = (pd.read_csv(cat_file)\n",
    "          .rename(columns = {'Symbol': 'ticker'})[['ticker', 'Listing Exchange', 'Market Category']]\n",
    "          )\n",
    "df = df.merge(cat_df, on = 'ticker', how = 'left')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "\n",
    "+ Previously, we produced a features data set.\n",
    "+ Most times, one or more [preprocessing steps](https://scikit-learn.org/stable/modules/preprocessing.html#) steps will be applied to data.\n",
    "+ The most practical way to apply them is by arranging them in `Pipeline` objects, wchich are sequential transformations applied to data. \n",
    "+ It is convenient for us to label these transformations and there is a standard way of doing so.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformations\n",
    "\n",
    "+ Transformations are classes that implement `fit` and `transform` methods.\n",
    "\n",
    "### StandardScaler\n",
    "\n",
    "+ For example, transform a numerical variable by standardizing it.\n",
    "- Standardization is removing the mean value of the feature and scale it by dividing non-constant features by their standard deviation.\n",
    "\n",
    "$$\n",
    "z = \\frac{x-\\mu}{\\sigma}\n",
    "$$\n",
    "\n",
    "\n",
    "+  Using [`StandardScaler`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html), one can do the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ticker', 'Date', 'Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume',\n",
       "       'source', 'Year', 'Close_lag_1', 'Listing Exchange_x',\n",
       "       'Market Category_x', 'Listing Exchange_y', 'Market Category_y',\n",
       "       'Listing Exchange', 'Market Category'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>source</th>\n",
       "      <th>Year</th>\n",
       "      <th>...</th>\n",
       "      <th>Market Category_x</th>\n",
       "      <th>Listing Exchange_y</th>\n",
       "      <th>Market Category_y</th>\n",
       "      <th>Listing Exchange</th>\n",
       "      <th>Market Category</th>\n",
       "      <th>returns</th>\n",
       "      <th>positive_return</th>\n",
       "      <th>hi_lo</th>\n",
       "      <th>op_cl</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>2014-01-03</td>\n",
       "      <td>40.336193</td>\n",
       "      <td>41.022888</td>\n",
       "      <td>40.243206</td>\n",
       "      <td>40.715309</td>\n",
       "      <td>38.229481</td>\n",
       "      <td>2609600.0</td>\n",
       "      <td>A.csv</td>\n",
       "      <td>2014</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>N</td>\n",
       "      <td></td>\n",
       "      <td>N</td>\n",
       "      <td></td>\n",
       "      <td>0.012631</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.779682</td>\n",
       "      <td>0.379116</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A</td>\n",
       "      <td>2014-01-06</td>\n",
       "      <td>41.058655</td>\n",
       "      <td>41.273247</td>\n",
       "      <td>40.457798</td>\n",
       "      <td>40.515022</td>\n",
       "      <td>38.041428</td>\n",
       "      <td>2484600.0</td>\n",
       "      <td>A.csv</td>\n",
       "      <td>2014</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>N</td>\n",
       "      <td></td>\n",
       "      <td>N</td>\n",
       "      <td></td>\n",
       "      <td>-0.004919</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.815449</td>\n",
       "      <td>-0.543633</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A</td>\n",
       "      <td>2014-01-07</td>\n",
       "      <td>40.736767</td>\n",
       "      <td>41.223175</td>\n",
       "      <td>40.722462</td>\n",
       "      <td>41.094421</td>\n",
       "      <td>38.585449</td>\n",
       "      <td>2045500.0</td>\n",
       "      <td>A.csv</td>\n",
       "      <td>2014</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>N</td>\n",
       "      <td></td>\n",
       "      <td>N</td>\n",
       "      <td></td>\n",
       "      <td>0.014301</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.500713</td>\n",
       "      <td>0.357655</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A</td>\n",
       "      <td>2014-01-08</td>\n",
       "      <td>41.008583</td>\n",
       "      <td>41.874107</td>\n",
       "      <td>40.894135</td>\n",
       "      <td>41.766811</td>\n",
       "      <td>39.216789</td>\n",
       "      <td>3717900.0</td>\n",
       "      <td>A.csv</td>\n",
       "      <td>2014</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>N</td>\n",
       "      <td></td>\n",
       "      <td>N</td>\n",
       "      <td></td>\n",
       "      <td>0.016362</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.979973</td>\n",
       "      <td>0.758228</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A</td>\n",
       "      <td>2014-01-09</td>\n",
       "      <td>41.773964</td>\n",
       "      <td>41.974251</td>\n",
       "      <td>41.394852</td>\n",
       "      <td>41.781116</td>\n",
       "      <td>39.230221</td>\n",
       "      <td>2457100.0</td>\n",
       "      <td>A.csv</td>\n",
       "      <td>2014</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>N</td>\n",
       "      <td></td>\n",
       "      <td>N</td>\n",
       "      <td></td>\n",
       "      <td>0.000342</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.579399</td>\n",
       "      <td>0.007153</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313504</th>\n",
       "      <td>ZEUS</td>\n",
       "      <td>2005-06-24</td>\n",
       "      <td>14.430000</td>\n",
       "      <td>14.550000</td>\n",
       "      <td>14.150000</td>\n",
       "      <td>14.170000</td>\n",
       "      <td>12.977926</td>\n",
       "      <td>201000.0</td>\n",
       "      <td>ZEUS.csv</td>\n",
       "      <td>2005</td>\n",
       "      <td>...</td>\n",
       "      <td>Q</td>\n",
       "      <td>Q</td>\n",
       "      <td>Q</td>\n",
       "      <td>Q</td>\n",
       "      <td>Q</td>\n",
       "      <td>-0.025447</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.400001</td>\n",
       "      <td>-0.260000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313505</th>\n",
       "      <td>ZEUS</td>\n",
       "      <td>2005-06-27</td>\n",
       "      <td>14.080000</td>\n",
       "      <td>14.330000</td>\n",
       "      <td>13.660000</td>\n",
       "      <td>13.730000</td>\n",
       "      <td>12.574939</td>\n",
       "      <td>273200.0</td>\n",
       "      <td>ZEUS.csv</td>\n",
       "      <td>2005</td>\n",
       "      <td>...</td>\n",
       "      <td>Q</td>\n",
       "      <td>Q</td>\n",
       "      <td>Q</td>\n",
       "      <td>Q</td>\n",
       "      <td>Q</td>\n",
       "      <td>-0.031052</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.670000</td>\n",
       "      <td>-0.350000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313506</th>\n",
       "      <td>ZEUS</td>\n",
       "      <td>2005-06-28</td>\n",
       "      <td>13.830000</td>\n",
       "      <td>14.360000</td>\n",
       "      <td>13.830000</td>\n",
       "      <td>14.150000</td>\n",
       "      <td>12.959603</td>\n",
       "      <td>290100.0</td>\n",
       "      <td>ZEUS.csv</td>\n",
       "      <td>2005</td>\n",
       "      <td>...</td>\n",
       "      <td>Q</td>\n",
       "      <td>Q</td>\n",
       "      <td>Q</td>\n",
       "      <td>Q</td>\n",
       "      <td>Q</td>\n",
       "      <td>0.030590</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.530000</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313507</th>\n",
       "      <td>ZEUS</td>\n",
       "      <td>2005-06-29</td>\n",
       "      <td>14.200000</td>\n",
       "      <td>14.250000</td>\n",
       "      <td>13.650000</td>\n",
       "      <td>13.840000</td>\n",
       "      <td>12.675684</td>\n",
       "      <td>145400.0</td>\n",
       "      <td>ZEUS.csv</td>\n",
       "      <td>2005</td>\n",
       "      <td>...</td>\n",
       "      <td>Q</td>\n",
       "      <td>Q</td>\n",
       "      <td>Q</td>\n",
       "      <td>Q</td>\n",
       "      <td>Q</td>\n",
       "      <td>-0.021908</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>-0.360000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313508</th>\n",
       "      <td>ZEUS</td>\n",
       "      <td>2005-06-30</td>\n",
       "      <td>13.810000</td>\n",
       "      <td>13.850000</td>\n",
       "      <td>13.300000</td>\n",
       "      <td>13.310000</td>\n",
       "      <td>12.190270</td>\n",
       "      <td>311400.0</td>\n",
       "      <td>ZEUS.csv</td>\n",
       "      <td>2005</td>\n",
       "      <td>...</td>\n",
       "      <td>Q</td>\n",
       "      <td>Q</td>\n",
       "      <td>Q</td>\n",
       "      <td>Q</td>\n",
       "      <td>Q</td>\n",
       "      <td>-0.038295</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>313422 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ticker       Date       Open       High        Low      Close  \\\n",
       "0           A 2014-01-03  40.336193  41.022888  40.243206  40.715309   \n",
       "1           A 2014-01-06  41.058655  41.273247  40.457798  40.515022   \n",
       "2           A 2014-01-07  40.736767  41.223175  40.722462  41.094421   \n",
       "3           A 2014-01-08  41.008583  41.874107  40.894135  41.766811   \n",
       "4           A 2014-01-09  41.773964  41.974251  41.394852  41.781116   \n",
       "...       ...        ...        ...        ...        ...        ...   \n",
       "313504   ZEUS 2005-06-24  14.430000  14.550000  14.150000  14.170000   \n",
       "313505   ZEUS 2005-06-27  14.080000  14.330000  13.660000  13.730000   \n",
       "313506   ZEUS 2005-06-28  13.830000  14.360000  13.830000  14.150000   \n",
       "313507   ZEUS 2005-06-29  14.200000  14.250000  13.650000  13.840000   \n",
       "313508   ZEUS 2005-06-30  13.810000  13.850000  13.300000  13.310000   \n",
       "\n",
       "        Adj Close     Volume    source  Year  ...  Market Category_x  \\\n",
       "0       38.229481  2609600.0     A.csv  2014  ...                      \n",
       "1       38.041428  2484600.0     A.csv  2014  ...                      \n",
       "2       38.585449  2045500.0     A.csv  2014  ...                      \n",
       "3       39.216789  3717900.0     A.csv  2014  ...                      \n",
       "4       39.230221  2457100.0     A.csv  2014  ...                      \n",
       "...           ...        ...       ...   ...  ...                ...   \n",
       "313504  12.977926   201000.0  ZEUS.csv  2005  ...                  Q   \n",
       "313505  12.574939   273200.0  ZEUS.csv  2005  ...                  Q   \n",
       "313506  12.959603   290100.0  ZEUS.csv  2005  ...                  Q   \n",
       "313507  12.675684   145400.0  ZEUS.csv  2005  ...                  Q   \n",
       "313508  12.190270   311400.0  ZEUS.csv  2005  ...                  Q   \n",
       "\n",
       "       Listing Exchange_y Market Category_y Listing Exchange Market Category  \\\n",
       "0                       N                                  N                   \n",
       "1                       N                                  N                   \n",
       "2                       N                                  N                   \n",
       "3                       N                                  N                   \n",
       "4                       N                                  N                   \n",
       "...                   ...               ...              ...             ...   \n",
       "313504                  Q                 Q                Q               Q   \n",
       "313505                  Q                 Q                Q               Q   \n",
       "313506                  Q                 Q                Q               Q   \n",
       "313507                  Q                 Q                Q               Q   \n",
       "313508                  Q                 Q                Q               Q   \n",
       "\n",
       "         returns positive_return     hi_lo     op_cl  target  \n",
       "0       0.012631             1.0  0.779682  0.379116     0.0  \n",
       "1      -0.004919             0.0  0.815449 -0.543633     1.0  \n",
       "2       0.014301             1.0  0.500713  0.357655     1.0  \n",
       "3       0.016362             1.0  0.979973  0.758228     1.0  \n",
       "4       0.000342             1.0  0.579399  0.007153     1.0  \n",
       "...          ...             ...       ...       ...     ...  \n",
       "313504 -0.025447             0.0  0.400001 -0.260000     0.0  \n",
       "313505 -0.031052             0.0  0.670000 -0.350000     1.0  \n",
       "313506  0.030590             1.0  0.530000  0.320000     0.0  \n",
       "313507 -0.021908             0.0  0.600000 -0.360000     0.0  \n",
       "313508 -0.038295             0.0  0.550000 -0.500000     1.0  \n",
       "\n",
       "[313422 rows x 22 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = (df.assign(\n",
    "        returns = lambda x: x['Close']/x['Close_lag_1'] - 1, \n",
    "        positive_return = lambda x: 1.0*(x['returns'] > 0),\n",
    "        hi_lo = lambda x: x['High'] - x['Low'],\n",
    "        op_cl = lambda x: x['Close'] - x['Open']\n",
    "    ).groupby(['ticker'], group_keys=False).apply(\n",
    "        lambda x: x.assign(target = x['positive_return'].shift(-1))\n",
    "    )\n",
    "    .reset_index(drop=True)\n",
    "    .dropna(subset = ['target'])\n",
    "    )\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "returns = df[['returns']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>StandardScaler()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "StandardScaler()"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a StandardScaler object\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "std_scaler = StandardScaler()\n",
    "\n",
    "\n",
    "# Fit the StandardScaler object with the returns data\n",
    "std_scaler.fit(returns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>returns</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3.134220e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-3.513924e-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.000002e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-6.374665e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-2.707055e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-2.664992e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>-2.624444e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.530226e+02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            returns\n",
       "count  3.134220e+05\n",
       "mean  -3.513924e-19\n",
       "std    1.000002e+00\n",
       "min   -6.374665e-03\n",
       "25%   -2.707055e-03\n",
       "50%   -2.664992e-03\n",
       "75%   -2.624444e-03\n",
       "max    5.530226e+02"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transform the returns data using the fitted scaler\n",
    "\n",
    "scaled_returns_np = std_scaler.transform(returns)\n",
    "scaled_returns = pd.DataFrame(scaled_returns_np, columns=returns.columns)\n",
    "scaled_returns.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  OneHotEncoder\n",
    "\n",
    "+ Categorical features can be encoded as numerical values using `OneHotEncoder`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='Listing Exchange'>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkIAAAGyCAYAAAAI3auEAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA8Y0lEQVR4nO3de1wU96H///cKsiKBDUpgswkR84hFDeaGqaJtSauClkvSNDUNdhMaDybFSKmQi/UkUc8J5oLoiTxiE2uK9VLaHsWTxISAidFQr0FJRQ3m4gUriK3rosQA4vz+yNf5dUWNJhiUeT0fj/ljZ94z8xn3kfLuZ2d2bYZhGAIAALCgbp09AAAAgM5CEQIAAJZFEQIAAJZFEQIAAJZFEQIAAJZFEQIAAJZFEQIAAJZFEQIAAJZFEQIAAJZFEQIAAJZ1wUVo7dq1SklJkcvlks1m04oVK9pldu7cqdTUVDkcDgUHB2vo0KHat2+fub25uVmTJk1SWFiYgoKClJqaqv379/scw+PxyO12y+FwyOFwyO1268iRIz6Zffv2KSUlRUFBQQoLC1NWVpZaWlp8Mtu2bVN8fLwCAwN1zTXXaMaMGeJXRQAAgPQ1ilBTU5NuvvlmFRYWnnH7p59+qu9973vq37+/3nvvPX344Yd68skn1aNHDzOTnZ2tkpISFRcXq6KiQseOHVNycrLa2trMTFpamqqqqlRaWqrS0lJVVVXJ7Xab29va2pSUlKSmpiZVVFSouLhYy5YtU05OjplpbGzUqFGj5HK5tHnzZs2dO1f5+fkqKCi40MsGAABdkO2b/OiqzWZTSUmJ7rrrLnPdz3/+c3Xv3l2LFi064z5er1dXXXWVFi1apHvvvVeSdODAAUVGRurNN99UYmKidu7cqYEDB2rDhg0aMmSIJGnDhg2Ki4vTRx99pOjoaL311ltKTk5WbW2tXC6XJKm4uFjp6elqaGhQSEiI5s2bpylTpujgwYOy2+2SpGeffVZz587V/v37ZbPZvvIaT548qQMHDig4OPi88gAAoPMZhqGjR4/K5XKpW7dzzPsY34Ako6SkxHzd1tZmXHHFFcaMGTOMhIQE46qrrjK++93v+mTeeecdQ5Jx+PBhn2PddNNNxlNPPWUYhmEsWLDAcDgc7c7ncDiMV1991TAMw3jyySeNm266yWf74cOHDUnGu+++axiGYbjdbiM1NdUns2XLFkOS8dlnn53xmr744gvD6/Way44dOwxJLCwsLCwsLJfhUltbe84u468O1NDQoGPHjunZZ5/Vf//3f+u5555TaWmp7r77bq1evVrx8fGqr69XQECAQkNDffaNiIhQfX29JKm+vl7h4eHtjh8eHu6TiYiI8NkeGhqqgIAAn0xUVFS785za1rdv33bnmDlzpqZPn95ufW1trUJCQs7zXwIAAHSmxsZGRUZGKjg4+Jy5Di1CJ0+elCTdeeed+s1vfiNJuuWWW7Ru3Tr97ne/U3x8/Fn3NQzD56OnM30M1REZ4/99Eni2j7mmTJmiyZMnm69P/UOGhIRQhAAAuMx81W0tHfr4fFhYmPz9/TVw4ECf9QMGDDCfGnM6nWppaZHH4/HJNDQ0mLM1TqdTBw8ebHf8Q4cO+WROzfyc4vF41Nraes5MQ0ODJLWbTTrFbrebpYfyAwBA19ahRSggIEC33367ampqfNbv2rVLffr0kSTFxsaqe/fuKi8vN7fX1dWpurpaw4YNkyTFxcXJ6/Vq06ZNZmbjxo3yer0+merqatXV1ZmZsrIy2e12xcbGmpm1a9f6PFJfVlYml8vV7iMzAABgQee8g+gMjh49amzdutXYunWrIckoKCgwtm7dauzdu9cwDMNYvny50b17d+OVV14xPv74Y2Pu3LmGn5+f8f7775vHePjhh41rr73WWLVqlbFlyxbjRz/6kXHzzTcbJ06cMDOjR482brrpJmP9+vXG+vXrjUGDBhnJycnm9hMnThgxMTHGiBEjjC1bthirVq0yrr32WuORRx4xM0eOHDEiIiKM++67z9i2bZuxfPlyIyQkxMjPzz/v6/V6vYYkw+v1Xug/FQAA6CTn+/f7govQ6tWrz3hX9gMPPGBmFixYYNxwww1Gjx49jJtvvtlYsWKFzzGOHz9uPPLII0avXr2MwMBAIzk52di3b59P5l//+pcxbtw4Izg42AgODjbGjRtneDwen8zevXuNpKQkIzAw0OjVq5fxyCOPGF988YVP5u9//7vx/e9/37Db7YbT6TSmTZtmnDx58ryvlyIEAMDl53z/fn+j7xGygsbGRjkcDnm9Xu4XAgDgMnG+f7/5rTEAAGBZFCEAAGBZFCEAAGBZFCEAAGBZFCEAAGBZFCEAAGBZFCEAAGBZFCEAAGBZFCEAAGBZFCEAAGBZ/p09AJxb1BMrO3sInWLPs0mdPQQAgAUwIwQAACyLIgQAACyLIgQAACyLIgQAACyLIgQAACyLIgQAACyLIgQAACyLIgQAACyLIgQAACyLIgQAACyLIgQAACyLIgQAACyLIgQAACyLIgQAACyLIgQAACyLIgQAACyLIgQAACyLIgQAACyLIgQAACyLIgQAACyLIgQAACyLIgQAACyLIgQAACyLIgQAACzrgovQ2rVrlZKSIpfLJZvNphUrVpw1+9BDD8lms2nOnDk+65ubmzVp0iSFhYUpKChIqamp2r9/v0/G4/HI7XbL4XDI4XDI7XbryJEjPpl9+/YpJSVFQUFBCgsLU1ZWllpaWnwy27ZtU3x8vAIDA3XNNddoxowZMgzjQi8bAAB0QRdchJqamnTzzTersLDwnLkVK1Zo48aNcrlc7bZlZ2erpKRExcXFqqio0LFjx5ScnKy2tjYzk5aWpqqqKpWWlqq0tFRVVVVyu93m9ra2NiUlJampqUkVFRUqLi7WsmXLlJOTY2YaGxs1atQouVwubd68WXPnzlV+fr4KCgou9LIBAEAX5H+hO4wZM0Zjxow5Z+Yf//iHHnnkEb399ttKSkry2eb1erVgwQItWrRII0eOlCQtXrxYkZGRWrVqlRITE7Vz506VlpZqw4YNGjJkiCRp/vz5iouLU01NjaKjo1VWVqYdO3aotrbWLFuzZs1Senq6nnnmGYWEhGjJkiX64osvVFRUJLvdrpiYGO3atUsFBQWaPHmybDbbhV4+AADoQjr8HqGTJ0/K7Xbr0Ucf1Y033thue2VlpVpbW5WQkGCuc7lciomJ0bp16yRJ69evl8PhMEuQJA0dOlQOh8MnExMT4zPjlJiYqObmZlVWVpqZ+Ph42e12n8yBAwe0Z8+eM46/ublZjY2NPgsAAOiaOrwIPffcc/L391dWVtYZt9fX1ysgIEChoaE+6yMiIlRfX29mwsPD2+0bHh7uk4mIiPDZHhoaqoCAgHNmTr0+lTndzJkzzfuSHA6HIiMjv+qSAQDAZapDi1BlZaX+53/+R0VFRRf8sZNhGD77nGn/jsiculH6bOObMmWKvF6vudTW1l7QdQAAgMtHhxah999/Xw0NDbruuuvk7+8vf39/7d27Vzk5OYqKipIkOZ1OtbS0yOPx+Ozb0NBgztY4nU4dPHiw3fEPHTrkkzl9Vsfj8ai1tfWcmYaGBklqN1N0it1uV0hIiM8CAAC6pg4tQm63W3//+99VVVVlLi6XS48++qjefvttSVJsbKy6d++u8vJyc7+6ujpVV1dr2LBhkqS4uDh5vV5t2rTJzGzcuFFer9cnU11drbq6OjNTVlYmu92u2NhYM7N27VqfR+rLysrkcrnMYgYAAKzrgp8aO3bsmD755BPz9e7du1VVVaVevXrpuuuuU+/evX3y3bt3l9PpVHR0tCTJ4XBo/PjxysnJUe/evdWrVy/l5uZq0KBB5lNkAwYM0OjRo5WRkaGXX35ZkjRhwgQlJyebx0lISNDAgQPldrv1wgsv6PDhw8rNzVVGRoY5i5OWlqbp06crPT1dv/3tb/Xxxx8rLy9PTz31FE+MAQCACy9CH3zwgX74wx+arydPnixJeuCBB1RUVHRex5g9e7b8/f01duxYHT9+XCNGjFBRUZH8/PzMzJIlS5SVlWU+XZaamurz3UV+fn5auXKlMjMzNXz4cAUGBiotLU35+flmxuFwqLy8XBMnTtTgwYMVGhqqyZMnm2MGAADWZjP4muVzamxslMPhkNfr7ZT7haKeWPmtn/NSsOfZpK8OAQBwFuf795vfGgMAAJZFEQIAAJZFEQIAAJZFEQIAAJZFEQIAAJZFEQIAAJZFEQIAAJZFEQIAAJZFEQIAAJZFEQIAAJZFEQIAAJZFEQIAAJZFEQIAAJZFEQIAAJZFEQIAAJZFEQIAAJZFEQIAAJZFEQIAAJZFEQIAAJZFEQIAAJZFEQIAAJZFEQIAAJZFEQIAAJZFEQIAAJZFEQIAAJZFEQIAAJZFEQIAAJZFEQIAAJZFEQIAAJZFEQIAAJZFEQIAAJZFEQIAAJZFEQIAAJZFEQIAAJZFEQIAAJZ1wUVo7dq1SklJkcvlks1m04oVK8xtra2tevzxxzVo0CAFBQXJ5XLp/vvv14EDB3yO0dzcrEmTJiksLExBQUFKTU3V/v37fTIej0dut1sOh0MOh0Nut1tHjhzxyezbt08pKSkKCgpSWFiYsrKy1NLS4pPZtm2b4uPjFRgYqGuuuUYzZsyQYRgXetkAAKALuuAi1NTUpJtvvlmFhYXttn3++efasmWLnnzySW3ZskXLly/Xrl27lJqa6pPLzs5WSUmJiouLVVFRoWPHjik5OVltbW1mJi0tTVVVVSotLVVpaamqqqrkdrvN7W1tbUpKSlJTU5MqKipUXFysZcuWKScnx8w0NjZq1KhRcrlc2rx5s+bOnav8/HwVFBRc6GUDAIAuyGZ8g+kRm82mkpIS3XXXXWfNbN68Wd/97ne1d+9eXXfddfJ6vbrqqqu0aNEi3XvvvZKkAwcOKDIyUm+++aYSExO1c+dODRw4UBs2bNCQIUMkSRs2bFBcXJw++ugjRUdH66233lJycrJqa2vlcrkkScXFxUpPT1dDQ4NCQkI0b948TZkyRQcPHpTdbpckPfvss5o7d672798vm832ldfY2Ngoh8Mhr9erkJCQr/tP9bVFPbHyWz/npWDPs0mdPQQAwGXsfP9+X/R7hLxer2w2m6688kpJUmVlpVpbW5WQkGBmXC6XYmJitG7dOknS+vXr5XA4zBIkSUOHDpXD4fDJxMTEmCVIkhITE9Xc3KzKykozEx8fb5agU5kDBw5oz549Zxxvc3OzGhsbfRYAANA1XdQi9MUXX+iJJ55QWlqa2cbq6+sVEBCg0NBQn2xERITq6+vNTHh4eLvjhYeH+2QiIiJ8toeGhiogIOCcmVOvT2VON3PmTPO+JIfDocjIyAu9bAAAcJm4aEWotbVVP//5z3Xy5Em99NJLX5k3DMPno6ozfWzVEZlTnwSe7WOxKVOmyOv1mkttbe1Xjh0AAFyeLkoRam1t1dixY7V7926Vl5f7fDbndDrV0tIij8fjs09DQ4M5W+N0OnXw4MF2xz106JBP5vRZHY/Ho9bW1nNmGhoaJKndTNEpdrtdISEhPgsAAOiaOrwInSpBH3/8sVatWqXevXv7bI+NjVX37t1VXl5urqurq1N1dbWGDRsmSYqLi5PX69WmTZvMzMaNG+X1en0y1dXVqqurMzNlZWWy2+2KjY01M2vXrvV5pL6srEwul0tRUVEdfekAAOAy43+hOxw7dkyffPKJ+Xr37t2qqqpSr1695HK5dM8992jLli1644031NbWZs7I9OrVSwEBAXI4HBo/frxycnLUu3dv9erVS7m5uRo0aJBGjhwpSRowYIBGjx6tjIwMvfzyy5KkCRMmKDk5WdHR0ZKkhIQEDRw4UG63Wy+88IIOHz6s3NxcZWRkmLM4aWlpmj59utLT0/Xb3/5WH3/8sfLy8vTUU0+d1xNjwLeNpwQB4Nt1wUXogw8+0A9/+EPz9eTJkyVJDzzwgKZNm6bXXntNknTLLbf47Ld69WrdcccdkqTZs2fL399fY8eO1fHjxzVixAgVFRXJz8/PzC9ZskRZWVnm02Wpqak+313k5+enlStXKjMzU8OHD1dgYKDS0tKUn59vZhwOh8rLyzVx4kQNHjxYoaGhmjx5sjlmAABgbd/oe4SsgO8R6hxWnSHg/QaAjnHJfI8QAADApYoiBAAALIsiBAAALIsiBAAALIsiBAAALIsiBAAALIsiBAAALIsiBAAALIsiBAAALIsiBAAALIsiBAAALIsiBAAALIsiBAAALIsiBAAALIsiBAAALIsiBAAALIsiBAAALIsiBAAALIsiBAAALIsiBAAALIsiBAAALIsiBAAALIsiBAAALIsiBAAALIsiBAAALIsiBAAALIsiBAAALIsiBAAALIsiBAAALIsiBAAALIsiBAAALIsiBAAALIsiBAAALIsiBAAALIsiBAAALOuCi9DatWuVkpIil8slm82mFStW+Gw3DEPTpk2Ty+VSYGCg7rjjDm3fvt0n09zcrEmTJiksLExBQUFKTU3V/v37fTIej0dut1sOh0MOh0Nut1tHjhzxyezbt08pKSkKCgpSWFiYsrKy1NLS4pPZtm2b4uPjFRgYqGuuuUYzZsyQYRgXetkAAKALuuAi1NTUpJtvvlmFhYVn3P7888+roKBAhYWF2rx5s5xOp0aNGqWjR4+amezsbJWUlKi4uFgVFRU6duyYkpOT1dbWZmbS0tJUVVWl0tJSlZaWqqqqSm6329ze1tampKQkNTU1qaKiQsXFxVq2bJlycnLMTGNjo0aNGiWXy6XNmzdr7ty5ys/PV0FBwYVeNgAA6IL8L3SHMWPGaMyYMWfcZhiG5syZo6lTp+ruu++WJC1cuFARERFaunSpHnroIXm9Xi1YsECLFi3SyJEjJUmLFy9WZGSkVq1apcTERO3cuVOlpaXasGGDhgwZIkmaP3++4uLiVFNTo+joaJWVlWnHjh2qra2Vy+WSJM2aNUvp6el65plnFBISoiVLluiLL75QUVGR7Ha7YmJitGvXLhUUFGjy5Mmy2Wxf6x8NAAB0DR16j9Du3btVX1+vhIQEc53dbld8fLzWrVsnSaqsrFRra6tPxuVyKSYmxsysX79eDofDLEGSNHToUDkcDp9MTEyMWYIkKTExUc3NzaqsrDQz8fHxstvtPpkDBw5oz549Z7yG5uZmNTY2+iwAAKBr6tAiVF9fL0mKiIjwWR8REWFuq6+vV0BAgEJDQ8+ZCQ8Pb3f88PBwn8zp5wkNDVVAQMA5M6den8qcbubMmeZ9SQ6HQ5GRkV994QAA4LJ0UZ4aO/0jJ8MwvvJjqNMzZ8p3RObUjdJnG8+UKVPk9XrNpba29pzjBgAAl68OLUJOp1NS+9mWhoYGcybG6XSqpaVFHo/nnJmDBw+2O/6hQ4d8Mqefx+PxqLW19ZyZhoYGSe1nrU6x2+0KCQnxWQAAQNfUoUWob9++cjqdKi8vN9e1tLRozZo1GjZsmCQpNjZW3bt398nU1dWpurrazMTFxcnr9WrTpk1mZuPGjfJ6vT6Z6upq1dXVmZmysjLZ7XbFxsaambVr1/o8Ul9WViaXy6WoqKiOvHQAAHAZuuAidOzYMVVVVamqqkrSlzdIV1VVad++fbLZbMrOzlZeXp5KSkpUXV2t9PR09ezZU2lpaZIkh8Oh8ePHKycnR++88462bt2qX/ziFxo0aJD5FNmAAQM0evRoZWRkaMOGDdqwYYMyMjKUnJys6OhoSVJCQoIGDhwot9utrVu36p133lFubq4yMjLMWZy0tDTZ7Xalp6erurpaJSUlysvL44kxAAAg6Ws8Pv/BBx/ohz/8ofl68uTJkqQHHnhARUVFeuyxx3T8+HFlZmbK4/FoyJAhKisrU3BwsLnP7Nmz5e/vr7Fjx+r48eMaMWKEioqK5OfnZ2aWLFmirKws8+my1NRUn+8u8vPz08qVK5WZmanhw4crMDBQaWlpys/PNzMOh0Pl5eWaOHGiBg8erNDQUE2ePNkcMwAAsDabwdcsn1NjY6McDoe8Xm+n3C8U9cTKb/2cl4I9zyZ19hA6Be83AHSM8/37zW+NAQAAy6IIAQAAy6IIAQAAy6IIAQAAy6IIAQAAy6IIAQAAy6IIAQAAy6IIAQAAy6IIAQAAy6IIAQAAy6IIAQAAy6IIAQAAy6IIAQAAy6IIAQAAy6IIAQAAy6IIAQAAy6IIAQAAy6IIAQAAy6IIAQAAy6IIAQAAy6IIAQAAy6IIAQAAy6IIAQAAy6IIAQAAy6IIAQAAy6IIAQAAy6IIAQAAy6IIAQAAy6IIAQAAy6IIAQAAy6IIAQAAy6IIAQAAy6IIAQAAy6IIAQAAy6IIAQAAy+rwInTixAn953/+p/r27avAwEBdf/31mjFjhk6ePGlmDMPQtGnT5HK5FBgYqDvuuEPbt2/3OU5zc7MmTZqksLAwBQUFKTU1Vfv37/fJeDweud1uORwOORwOud1uHTlyxCezb98+paSkKCgoSGFhYcrKylJLS0tHXzYAALgMdXgReu655/S73/1OhYWF2rlzp55//nm98MILmjt3rpl5/vnnVVBQoMLCQm3evFlOp1OjRo3S0aNHzUx2drZKSkpUXFysiooKHTt2TMnJyWprazMzaWlpqqqqUmlpqUpLS1VVVSW3221ub2trU1JSkpqamlRRUaHi4mItW7ZMOTk5HX3ZAADgMuTf0Qdcv3697rzzTiUlJUmSoqKi9Kc//UkffPCBpC9ng+bMmaOpU6fq7rvvliQtXLhQERERWrp0qR566CF5vV4tWLBAixYt0siRIyVJixcvVmRkpFatWqXExETt3LlTpaWl2rBhg4YMGSJJmj9/vuLi4lRTU6Po6GiVlZVpx44dqq2tlcvlkiTNmjVL6enpeuaZZxQSEtLRlw8AAC4jHT4j9L3vfU/vvPOOdu3aJUn68MMPVVFRoR//+MeSpN27d6u+vl4JCQnmPna7XfHx8Vq3bp0kqbKyUq2trT4Zl8ulmJgYM7N+/Xo5HA6zBEnS0KFD5XA4fDIxMTFmCZKkxMRENTc3q7Ky8ozjb25uVmNjo88CAAC6pg6fEXr88cfl9XrVv39/+fn5qa2tTc8884zuu+8+SVJ9fb0kKSIiwme/iIgI7d2718wEBAQoNDS0XebU/vX19QoPD293/vDwcJ/M6ecJDQ1VQECAmTndzJkzNX369Au9bAAAcBnq8BmhP//5z1q8eLGWLl2qLVu2aOHChcrPz9fChQt9cjabzee1YRjt1p3u9MyZ8l8n8++mTJkir9drLrW1teccEwAAuHx1+IzQo48+qieeeEI///nPJUmDBg3S3r17NXPmTD3wwANyOp2Svpytufrqq839GhoazNkbp9OplpYWeTwen1mhhoYGDRs2zMwcPHiw3fkPHTrkc5yNGzf6bPd4PGptbW03U3SK3W6X3W7/upcPAAAuIx0+I/T555+rWzffw/r5+ZmPz/ft21dOp1Pl5eXm9paWFq1Zs8YsObGxserevbtPpq6uTtXV1WYmLi5OXq9XmzZtMjMbN26U1+v1yVRXV6uurs7MlJWVyW63KzY2toOvHAAAXG46fEYoJSVFzzzzjK677jrdeOON2rp1qwoKCvTggw9K+vKjquzsbOXl5alfv37q16+f8vLy1LNnT6WlpUmSHA6Hxo8fr5ycHPXu3Vu9evVSbm6uBg0aZD5FNmDAAI0ePVoZGRl6+eWXJUkTJkxQcnKyoqOjJUkJCQkaOHCg3G63XnjhBR0+fFi5ubnKyMjgiTEAANDxRWju3Ll68sknlZmZqYaGBrlcLj300EN66qmnzMxjjz2m48ePKzMzUx6PR0OGDFFZWZmCg4PNzOzZs+Xv76+xY8fq+PHjGjFihIqKiuTn52dmlixZoqysLPPpstTUVBUWFprb/fz8tHLlSmVmZmr48OEKDAxUWlqa8vPzO/qyAQDAZchmGIbR2YO4lDU2NsrhcMjr9XbKLFLUEyu/9XNeCvY8m9TZQ+gUvN8A0DHO9+83vzUGAAAsiyIEAAAsiyIEAAAsiyIEAAAsiyIEAAAsiyIEAAAsiyIEAAAsiyIEAAAsiyIEAAAsiyIEAAAsiyIEAAAsiyIEAAAsiyIEAAAsiyIEAAAsiyIEAAAsiyIEAAAsiyIEAAAsiyIEAAAsiyIEAAAsiyIEAAAsiyIEAAAsiyIEAAAsiyIEAAAsiyIEAAAsiyIEAAAsiyIEAAAsiyIEAAAsiyIEAAAsiyIEAAAsiyIEAAAsiyIEAAAsiyIEAAAsiyIEAAAsiyIEAAAsiyIEAAAs66IUoX/84x/6xS9+od69e6tnz5665ZZbVFlZaW43DEPTpk2Ty+VSYGCg7rjjDm3fvt3nGM3NzZo0aZLCwsIUFBSk1NRU7d+/3yfj8XjkdrvlcDjkcDjkdrt15MgRn8y+ffuUkpKioKAghYWFKSsrSy0tLRfjsgEAwGWmw4uQx+PR8OHD1b17d7311lvasWOHZs2apSuvvNLMPP/88yooKFBhYaE2b94sp9OpUaNG6ejRo2YmOztbJSUlKi4uVkVFhY4dO6bk5GS1tbWZmbS0NFVVVam0tFSlpaWqqqqS2+02t7e1tSkpKUlNTU2qqKhQcXGxli1bppycnI6+bAAAcBmyGYZhdOQBn3jiCf3tb3/T+++/f8bthmHI5XIpOztbjz/+uKQvZ38iIiL03HPP6aGHHpLX69VVV12lRYsW6d5775UkHThwQJGRkXrzzTeVmJionTt3auDAgdqwYYOGDBkiSdqwYYPi4uL00UcfKTo6Wm+99ZaSk5NVW1srl8slSSouLlZ6eroaGhoUEhLyldfT2Ngoh8Mhr9d7XvmOFvXEym/9nJeCPc8mdfYQOgXvNwB0jPP9+93hM0KvvfaaBg8erJ/97GcKDw/Xrbfeqvnz55vbd+/erfr6eiUkJJjr7Ha74uPjtW7dOklSZWWlWltbfTIul0sxMTFmZv369XI4HGYJkqShQ4fK4XD4ZGJiYswSJEmJiYlqbm72+agOAABYU4cXoc8++0zz5s1Tv3799Pbbb+vhhx9WVlaW/vjHP0qS6uvrJUkRERE++0VERJjb6uvrFRAQoNDQ0HNmwsPD250/PDzcJ3P6eUJDQxUQEGBmTtfc3KzGxkafBQAAdE3+HX3AkydPavDgwcrLy5Mk3Xrrrdq+fbvmzZun+++/38zZbDaf/QzDaLfudKdnzpT/Opl/N3PmTE2fPv2c4wAAAF1Dh88IXX311Ro4cKDPugEDBmjfvn2SJKfTKUntZmQaGhrM2Run06mWlhZ5PJ5zZg4ePNju/IcOHfLJnH4ej8ej1tbWdjNFp0yZMkVer9dcamtrz+u6AQDA5afDi9Dw4cNVU1Pjs27Xrl3q06ePJKlv375yOp0qLy83t7e0tGjNmjUaNmyYJCk2Nlbdu3f3ydTV1am6utrMxMXFyev1atOmTWZm48aN8nq9Ppnq6mrV1dWZmbKyMtntdsXGxp5x/Ha7XSEhIT4LAADomjr8o7Hf/OY3GjZsmPLy8jR27Fht2rRJr7zyil555RVJX35UlZ2drby8PPXr10/9+vVTXl6eevbsqbS0NEmSw+HQ+PHjlZOTo969e6tXr17Kzc3VoEGDNHLkSElfzjKNHj1aGRkZevnllyVJEyZMUHJysqKjoyVJCQkJGjhwoNxut1544QUdPnxYubm5ysjIoOAAAICOL0K33367SkpKNGXKFM2YMUN9+/bVnDlzNG7cODPz2GOP6fjx48rMzJTH49GQIUNUVlam4OBgMzN79mz5+/tr7NixOn78uEaMGKGioiL5+fmZmSVLligrK8t8uiw1NVWFhYXmdj8/P61cuVKZmZkaPny4AgMDlZaWpvz8/I6+bAAAcBnq8O8R6mr4HqHOYdXvleH9BoCO0WnfIwQAAHC5oAgBAADLoggBAADLoggBAADLoggBAADLoggBAADLoggBAADLoggBAADLoggBAADLoggBAADLoggBAADLoggBAADLoggBAADLoggBAADLoggBAADLoggBAADLoggBAADLoggBAADLoggBAADLoggBAADLoggBAADLoggBAADLoggBAADLoggBAADLoggBAADLoggBAADLoggBAADLoggBAADLoggBAADLoggBAADLoggBAADLoggBAADLoggBAADLoggBAADLoggBAADLoggBAADLuuhFaObMmbLZbMrOzjbXGYahadOmyeVyKTAwUHfccYe2b9/us19zc7MmTZqksLAwBQUFKTU1Vfv37/fJeDweud1uORwOORwOud1uHTlyxCezb98+paSkKCgoSGFhYcrKylJLS8vFulwAAHAZuahFaPPmzXrllVd00003+ax//vnnVVBQoMLCQm3evFlOp1OjRo3S0aNHzUx2drZKSkpUXFysiooKHTt2TMnJyWprazMzaWlpqqqqUmlpqUpLS1VVVSW3221ub2trU1JSkpqamlRRUaHi4mItW7ZMOTk5F/OyAQDAZeKiFaFjx45p3Lhxmj9/vkJDQ831hmFozpw5mjp1qu6++27FxMRo4cKF+vzzz7V06VJJktfr1YIFCzRr1iyNHDlSt956qxYvXqxt27Zp1apVkqSdO3eqtLRUv//97xUXF6e4uDjNnz9fb7zxhmpqaiRJZWVl2rFjhxYvXqxbb71VI0eO1KxZszR//nw1NjZerEsHAACXiYtWhCZOnKikpCSNHDnSZ/3u3btVX1+vhIQEc53dbld8fLzWrVsnSaqsrFRra6tPxuVyKSYmxsysX79eDodDQ4YMMTNDhw6Vw+HwycTExMjlcpmZxMRENTc3q7Ky8ozjbm5uVmNjo88CAAC6Jv+LcdDi4mJt2bJFmzdvbretvr5ekhQREeGzPiIiQnv37jUzAQEBPjNJpzKn9q+vr1d4eHi744eHh/tkTj9PaGioAgICzMzpZs6cqenTp5/PZQIAgMtch88I1dbW6te//rUWL16sHj16nDVns9l8XhuG0W7d6U7PnCn/dTL/bsqUKfJ6veZSW1t7zjEBAIDLV4cXocrKSjU0NCg2Nlb+/v7y9/fXmjVr9OKLL8rf39+coTl9RqahocHc5nQ61dLSIo/Hc87MwYMH253/0KFDPpnTz+PxeNTa2tpupugUu92ukJAQnwUAAHRNHV6ERowYoW3btqmqqspcBg8erHHjxqmqqkrXX3+9nE6nysvLzX1aWlq0Zs0aDRs2TJIUGxur7t27+2Tq6upUXV1tZuLi4uT1erVp0yYzs3HjRnm9Xp9MdXW16urqzExZWZnsdrtiY2M7+tIBAMBlpsPvEQoODlZMTIzPuqCgIPXu3dtcn52drby8PPXr10/9+vVTXl6eevbsqbS0NEmSw+HQ+PHjlZOTo969e6tXr17Kzc3VoEGDzJuvBwwYoNGjRysjI0Mvv/yyJGnChAlKTk5WdHS0JCkhIUEDBw6U2+3WCy+8oMOHDys3N1cZGRnM9AAAgItzs/RXeeyxx3T8+HFlZmbK4/FoyJAhKisrU3BwsJmZPXu2/P39NXbsWB0/flwjRoxQUVGR/Pz8zMySJUuUlZVlPl2WmpqqwsJCc7ufn59WrlypzMxMDR8+XIGBgUpLS1N+fv63d7EAAOCSZTMMw+jsQVzKGhsb5XA45PV6O2UWKeqJld/6OS8Fe55N6uwhdArebwDoGOf795vfGgMAAJZFEQIAAJZFEQIAAJZFEQIAAJZFEQIAAJZFEQIAAJbVKd8jBADg6xKASwEzQgAAwLIoQgAAwLIoQgAAwLIoQgAAwLIoQgAAwLIoQgAAwLIoQgAAwLIoQgAAwLIoQgAAwLIoQgAAwLIoQgAAwLIoQgAAwLIoQgAAwLIoQgAAwLIoQgAAwLIoQgAAwLIoQgAAwLIoQgAAwLIoQgAAwLIoQgAAwLIoQgAAwLIoQgAAwLIoQgAAwLIoQgAAwLIoQgAAwLIoQgAAwLIoQgAAwLIoQgAAwLI6vAjNnDlTt99+u4KDgxUeHq677rpLNTU1PhnDMDRt2jS5XC4FBgbqjjvu0Pbt230yzc3NmjRpksLCwhQUFKTU1FTt37/fJ+PxeOR2u+VwOORwOOR2u3XkyBGfzL59+5SSkqKgoCCFhYUpKytLLS0tHX3ZAADgMtThRWjNmjWaOHGiNmzYoPLycp04cUIJCQlqamoyM88//7wKCgpUWFiozZs3y+l0atSoUTp69KiZyc7OVklJiYqLi1VRUaFjx44pOTlZbW1tZiYtLU1VVVUqLS1VaWmpqqqq5Ha7ze1tbW1KSkpSU1OTKioqVFxcrGXLliknJ6ejLxsAAFyG/Dv6gKWlpT6v//CHPyg8PFyVlZX6wQ9+IMMwNGfOHE2dOlV33323JGnhwoWKiIjQ0qVL9dBDD8nr9WrBggVatGiRRo4cKUlavHixIiMjtWrVKiUmJmrnzp0qLS3Vhg0bNGTIEEnS/PnzFRcXp5qaGkVHR6usrEw7duxQbW2tXC6XJGnWrFlKT0/XM888o5CQkI6+fAAAcBm56PcIeb1eSVKvXr0kSbt371Z9fb0SEhLMjN1uV3x8vNatWydJqqysVGtrq0/G5XIpJibGzKxfv14Oh8MsQZI0dOhQORwOn0xMTIxZgiQpMTFRzc3NqqysPON4m5ub1djY6LMAAICu6aIWIcMwNHnyZH3ve99TTEyMJKm+vl6SFBER4ZONiIgwt9XX1ysgIEChoaHnzISHh7c7Z3h4uE/m9POEhoYqICDAzJxu5syZ5j1HDodDkZGRF3rZAADgMnFRi9Ajjzyiv//97/rTn/7UbpvNZvN5bRhGu3WnOz1zpvzXyfy7KVOmyOv1mkttbe05xwQAAC5fF60ITZo0Sa+99ppWr16ta6+91lzvdDolqd2MTENDgzl743Q61dLSIo/Hc87MwYMH25330KFDPpnTz+PxeNTa2tpupugUu92ukJAQnwUAAHRNHV6EDMPQI488ouXLl+vdd99V3759fbb37dtXTqdT5eXl5rqWlhatWbNGw4YNkyTFxsaqe/fuPpm6ujpVV1ebmbi4OHm9Xm3atMnMbNy4UV6v1ydTXV2turo6M1NWVia73a7Y2NiOvnQAAHCZ6fCnxiZOnKilS5fq//7v/xQcHGzOyDgcDgUGBspmsyk7O1t5eXnq16+f+vXrp7y8PPXs2VNpaWlmdvz48crJyVHv3r3Vq1cv5ebmatCgQeZTZAMGDNDo0aOVkZGhl19+WZI0YcIEJScnKzo6WpKUkJCggQMHyu1264UXXtDhw4eVm5urjIwMZnoAAEDHF6F58+ZJku644w6f9X/4wx+Unp4uSXrsscd0/PhxZWZmyuPxaMiQISorK1NwcLCZnz17tvz9/TV27FgdP35cI0aMUFFRkfz8/MzMkiVLlJWVZT5dlpqaqsLCQnO7n5+fVq5cqczMTA0fPlyBgYFKS0tTfn5+R182AAC4DNkMwzA6exCXssbGRjkcDnm93k6ZRYp6YuW3fs5LwZ5nkzp7CJ2C99taeL+Bi+d8/37zW2MAAMCyKEIAAMCyKEIAAMCyKEIAAMCyKEIAAMCyKEIAAMCyKEIAAMCyKEIAAMCyKEIAAMCyKEIAAMCyKEIAAMCyKEIAAMCyKEIAAMCyKEIAAMCyKEIAAMCyKEIAAMCyKEIAAMCyKEIAAMCyKEIAAMCyKEIAAMCy/Dt7AAAAWEHUEys7ewidYs+zSZ09hHNiRggAAFgWRQgAAFgWRQgAAFgWRQgAAFgWRQgAAFgWRQgAAFgWRQgAAFgWRQgAAFgWRQgAAFgWRQgAAFgWRQgAAFgWRQgAAFgWRQgAAFgWRQgAAFiWJYrQSy+9pL59+6pHjx6KjY3V+++/39lDAgAAl4AuX4T+/Oc/Kzs7W1OnTtXWrVv1/e9/X2PGjNG+ffs6e2gAAKCTdfkiVFBQoPHjx+s//uM/NGDAAM2ZM0eRkZGaN29eZw8NAAB0Mv/OHsDF1NLSosrKSj3xxBM+6xMSErRu3boz7tPc3Kzm5mbztdfrlSQ1NjZevIGew8nmzzvlvJ2ts/69Oxvvt7XwflsL73fnnNcwjHPmunQR+uc//6m2tjZFRET4rI+IiFB9ff0Z95k5c6amT5/ebn1kZORFGSPOzDGns0eAbxPvt7XwfltLZ7/fR48elcPhOOv2Ll2ETrHZbD6vDcNot+6UKVOmaPLkyebrkydP6vDhw+rdu/dZ9+mKGhsbFRkZqdraWoWEhHT2cHCR8X5bC++3tVj1/TYMQ0ePHpXL5TpnrksXobCwMPn5+bWb/WloaGg3S3SK3W6X3W73WXfllVderCFe8kJCQiz1H47V8X5bC++3tVjx/T7XTNApXfpm6YCAAMXGxqq8vNxnfXl5uYYNG9ZJowIAAJeKLj0jJEmTJ0+W2+3W4MGDFRcXp1deeUX79u3Tww8/3NlDAwAAnazLF6F7771X//rXvzRjxgzV1dUpJiZGb775pvr06dPZQ7uk2e12Pf300+0+JkTXxPttLbzf1sL7fW4246ueKwMAAOiiuvQ9QgAAAOdCEQIAAJZFEQIAAJZFEQIAAJZFEQIs7p///Kdlf/sJUlVVVWcPAehUFCHAgo4cOaKJEycqLCxMERERCg0NldPp1JQpU/T559b8YUgr8Xq9eumll3TbbbcpNja2s4cDdCoen4e6dev2lb+jZrPZdOLEiW9pRLiYDh8+rLi4OP3jH//QuHHjNGDAABmGoZ07d2rp0qXq37+/Kioq9OGHH2rjxo3Kysrq7CGjg7z77rt69dVXtXz5cvXp00c//elP9dOf/lS33nprZw8NHeTzzz/Xo48+qhUrVqi1tVUjR47Uiy++qLCwsM4e2iWry3+hIr5aSUnJWbetW7dOc+fOFX2565gxY4YCAgL06aeftvvNvRkzZighIUFut1tlZWV68cUXO2mU6Cj79+9XUVGRXn31VTU1NWns2LFqbW3VsmXLNHDgwM4eHjrY008/raKiIo0bN06BgYFaunSpfvWrX+mvf/1rZw/t0mUAZ7Bz507jrrvuMvz8/Iz777/f2Lt3b2cPCR2kT58+Rmlp6Vm3v/XWW4bNZjOmTZv2LY4KF8OYMWOM4OBg47777jPeeOMN48SJE4ZhGIa/v7+xffv2Th4dLobrr7/e+NOf/mS+3rhxo+Hv72++92iPj8bg48CBA3r66ae1cOFCJSYmaubMmYqJiensYaED2e12ffrpp7r22mvPuH3//v2Kiorio9AuwN/fX1lZWfrVr36lfv36meu7d++uDz/8kBmhLiggIEC7d+/WNddcY64LDAzUrl27FBkZ2Ykju3RxszQkfXnz5OOPP64bbrhB27dv1zvvvKPXX3+dEtQFhYWFac+ePWfdvnv3boWHh397A8JF8/777+vo0aMaPHiwhgwZosLCQh06dKizh4WLqK2tTQEBAT7r/P39+T8258CMEPT888/rueeek9PpVF5enu68887OHhIuovHjx+uTTz5ReXl5u//BbG5uVmJioq6//nq9+uqrnTRCdLTPP/9cxcXFevXVV7Vp0ya1tbWpoKBADz74oIKDgzt7eOhA3bp105gxY3x+YPX111/Xj370IwUFBZnrli9f3hnDuyRRhKBu3bopMDBQI0eOlJ+f31lz/IfTNezfv1+DBw+W3W7XxIkT1b9/f0nSjh079NJLL6m5uVmbN2/Wdddd18kjxcVQU1OjBQsWaNGiRTpy5IhGjRql1157rbOHhQ7yy1/+8rxyf/jDHy7ySC4fFCEoPT39Kx+fl/gPpyvZvXu3MjMzVVZWZj4RaLPZNGrUKBUWFuqGG27o5BHiYmtra9Prr7+uV199lSIES6MIARbm8Xj08ccfS5JuuOEG9erVq5NHBADfLooQAACwLJ4aAwAAlkURAgAAlkURAgAAlkURAvC12Gw2rVix4mvvP23aNN1yyy0dNp7O8t5778lms+nIkSOdPRQAXwNFCMAZpaen66677jrr9rq6Oo0ZM+a8jnWm0pSbm6t33nnnG4zw/EybNk02m63dcur7kwBYG78+D+BrcTqd32j/K664QldccUUHjebcbrzxRq1atcpnnb8///MHgBkhAF/Tv8/ytLS06JFHHtHVV1+tHj16KCoqSjNnzpQkRUVFSZJ+8pOfyGazma9P/2js1AxUfn6+rr76avXu3VsTJ05Ua2urmamrq1NSUpICAwPVt29fLV26VFFRUZozZ845x+rv7y+n0+mzhIWFSZI++ugj9ezZU0uXLjXzy5cvV48ePbRt2zZJX/70yGOPPabIyEjZ7Xb169dPCxYs8DlHZWWlBg8erJ49e2rYsGGqqakxt3366ae68847FRERoSuuuEK33357u2IWFRWlvLw882cvrrvuOr3yyis+mXXr1umWW25Rjx49NHjwYK1YsUI2m01VVVVmZseOHfrxj3+sK664QhEREXK73frnP/95zn8fwMooQgC+sRdffFGvvfaa/vKXv6impkaLFy82C8/mzZslffnN5HV1debrM1m9erU+/fRTrV69WgsXLlRRUZGKiorM7ffff78OHDig9957T8uWLdMrr7yihoaGbzT2/v37Kz8/X5mZmdq7d68OHDigjIwMPfvssxo0aJB53uLiYr344ovauXOnfve737WbzZo6dapmzZqlDz74QP7+/nrwwQfNbceOHdOPf/xjrVq1Slu3blViYqJSUlK0b98+n2PMmjVLgwcP1tatW5WZmalf/epX+uijjyRJR48eVUpKigYNGqQtW7bov/7rv/T444/77F9XV6f4+Hjdcsst+uCDD1RaWqqDBw9q7Nix3+jfCOjSDAA4gwceeMC48847z7pdklFSUmIYhmFMmjTJ+NGPfmScPHnyK7OnPP3008bNN9/sc74+ffoYJ06cMNf97Gc/M+69917DMAxj586dhiRj8+bN5vaPP/7YkGTMnj37rON8+umnjW7duhlBQUE+y/jx431ySUlJxve//31jxIgRxqhRo8xrqampMSQZ5eXlZzz+6tWrDUnGqlWrzHUrV640JBnHjx8/67gGDhxozJ0713zdp08f4xe/+IX5+uTJk0Z4eLgxb948wzAMY968eUbv3r19jjl//nxDkrF161bDMAzjySefNBISEnzOU1tba0gyampqzjoWwMr4kBzAN5aenq5Ro0YpOjpao0ePVnJyshISEi74ODfeeKPPD/9effXV5sdTNTU18vf312233WZuv+GGGxQaGvqVx42Ojm73e1qn/+r6q6++qu985zvq1q2bqqurzd/fq6qqkp+fn+Lj4895jptuusln3JLU0NCg6667Tk1NTZo+fbreeOMNHThwQCdOnNDx48fbzQj9+zFsNpucTqc541VTU6ObbrpJPXr0MDPf/e53ffavrKzU6tWrz3jv1aeffqrvfOc757wGwIooQgC+sdtuu027d+/WW2+9pVWrVmns2LEaOXKk/vd///eCjtO9e3ef1zabTSdPnpQk88dhT3e29f8uICDgK39I9sMPP1RTU5O6deum+vp6uVwuSVJgYOD5DN1n7KdK1KmxP/roo3r77beVn5+vG264QYGBgbrnnnvU0tJy1mOcOs6/X//pP458+rWfPHlSKSkpeu6559qN71Q5A+CLIgSgQ4SEhOjee+/Vvffeq3vuuUejR4/W4cOH1atXL3Xv3l1tbW3f6Pj9+/fXiRMntHXrVsXGxkqSPvnkkw75/p7Dhw8rPT1dU6dOVX19vcaNG6ctW7YoMDBQgwYN0smTJ7VmzRqNHDnyax3//fffV3p6un7yk59I+vKeoT179lzQMfr3768lS5aoublZdrtdkvTBBx/4ZG677TYtW7ZMUVFRPBUHnCdulgZwVl6vV1VVVT7L6R/nSNLs2bNVXFysjz76SLt27dJf//pXOZ1OXXnllZK+fCLqnXfeUX19vTwez9caS//+/TVy5EhNmDBBmzZt0tatWzVhwgQFBga2myk53YkTJ1RfX++zHDx40Nz+8MMPKzIyUv/5n/+pgoICGYah3Nxcc+wPPPCAHnzwQa1YsUK7d+/We++9p7/85S/nPfYbbrhBy5cvV1VVlT788EOlpaWZMz3n69Q+EyZM0M6dO80ZJun/n4GaOHGiDh8+rPvuu0+bNm3SZ599prKyMj344IPfuIgCXRVFCMBZvffee7r11lt9lqeeeqpd7oorrtBzzz2nwYMH6/bbb9eePXv05ptvqlu3L/8nZtasWSovL1dkZKRuvfXWrz2eP/7xj4qIiNAPfvAD/eQnP1FGRoaCg4N97ps5k+3bt+vqq6/2Wfr06WMe880339SiRYvk7++vnj17asmSJfr973+vN998U5I0b9483XPPPcrMzFT//v2VkZGhpqam8x737NmzFRoaqmHDhiklJUWJiYk+9zqdj5CQEL3++uuqqqrSLbfcoqlTp5rvxanrd7lc+tvf/qa2tjYlJiYqJiZGv/71r+VwOMz3AoAvm3E+H7ADwCVo//79ioyM1KpVqzRixIjOHs63bsmSJfrlL38pr9d73vcyAfDFh8gALhvvvvuujh07pkGDBqmurk6PPfaYoqKi9IMf/KCzh/at+OMf/6jrr79e11xzjT788EM9/vjjGjt2LCUI+AYoQgAuG62trfrtb3+rzz77TMHBwRo2bJiWLFnS7mmrrqq+vl5PPfWU6uvrdfXVV+tnP/uZnnnmmc4eFnBZ46MxAABgWdw9BwAALIsiBAAALIsiBAAALIsiBAAALIsiBAAALIsiBAAALIsiBAAALIsiBAAALIsiBAAALOv/A0CvDOwG9oZKAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['Listing Exchange'].value_counts().plot(kind = 'bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Use [`OneHotEncoder`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html) to encode a categorical variable as numerical.\n",
    "+ Important parameters:\n",
    "\n",
    "    - `categories` allows you to specify the categories to work with.\n",
    "    - `drop`: we can drop the `'first'` value (dummy encoding) or `'if_binary'`, a convenience setting for binary values.\n",
    "    - `handle_unknown` allows three options, `'error'`, `'ignore'`, and `'infrequent_if_exist'`, depending on what we want to do with new values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>OneHotEncoder(drop=&#x27;first&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" checked><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(drop=&#x27;first&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "OneHotEncoder(drop='first')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "onehot = OneHotEncoder(drop = 'first')\n",
    "onehot.fit(df[['Listing Exchange']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listing_enc = onehot.fit_transform(df[['Listing Exchange']])\n",
    "listing_enc.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipelines\n",
    "\n",
    "+ It is impractical and costly to manipulate data \"by hand\". \n",
    "+ To manage data preprocessing steps within the cross-validation process use `Pipeline` objects.\n",
    "+ A [`Pipeline`](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html) object allows us to sequentially apply transformation steps and, if required, a predictor.\n",
    "+ `Pipeline` objects compose transforms, i.e., classes that implement `transform` and `fit` methods.\n",
    "+ The purpose of `Pipeline` objects is to ensemble transforms and predictors to be used in cross-validation.\n",
    "+ A `Pipeline` is defined by a list of tuples.\n",
    "+ Each tuple is composed of `(\"name\", <ColumnTransformer>)`, the name of the step and the `<ColumnTransformer>` function of our chosing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, log_loss, cohen_kappa_score, f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;background-color: white;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;onehot&#x27;, OneHotEncoder(handle_unknown=&#x27;ignore&#x27;)),\n",
       "                (&#x27;knn&#x27;,\n",
       "                 DecisionTreeClassifier(criterion=&#x27;entropy&#x27;, max_depth=3))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;onehot&#x27;, OneHotEncoder(handle_unknown=&#x27;ignore&#x27;)),\n",
       "                (&#x27;knn&#x27;,\n",
       "                 DecisionTreeClassifier(criterion=&#x27;entropy&#x27;, max_depth=3))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(handle_unknown=&#x27;ignore&#x27;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(criterion=&#x27;entropy&#x27;, max_depth=3)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('onehot', OneHotEncoder(handle_unknown='ignore')),\n",
       "                ('knn',\n",
       "                 DecisionTreeClassifier(criterion='entropy', max_depth=3))])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe1 = Pipeline(\n",
    "    [\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore')),\n",
    "        ('knn', DecisionTreeClassifier(criterion = 'entropy', max_depth=3))\n",
    "\n",
    "    ]\n",
    ")\n",
    "pipe1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-7 {color: black;background-color: white;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;onehot&#x27;, OneHotEncoder(handle_unknown=&#x27;ignore&#x27;)),\n",
       "                (&#x27;knn&#x27;,\n",
       "                 DecisionTreeClassifier(criterion=&#x27;entropy&#x27;, max_depth=3))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;onehot&#x27;, OneHotEncoder(handle_unknown=&#x27;ignore&#x27;)),\n",
       "                (&#x27;knn&#x27;,\n",
       "                 DecisionTreeClassifier(criterion=&#x27;entropy&#x27;, max_depth=3))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(handle_unknown=&#x27;ignore&#x27;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" ><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(criterion=&#x27;entropy&#x27;, max_depth=3)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('onehot', OneHotEncoder(handle_unknown='ignore')),\n",
       "                ('knn',\n",
       "                 DecisionTreeClassifier(criterion='entropy', max_depth=3))])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X0 = df[['Listing Exchange', 'Market Category']]\n",
    "Y0 = df['target']\n",
    "X0_train, X0_test, Y0_train, Y0_test = train_test_split(X0, Y0, test_size=0.2, random_state=42)\n",
    "\n",
    "pipe1.fit(X0_train, Y0_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred_train = pipe1.predict(X0_train)\n",
    "Y_pred_test = pipe1.predict(X0_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_poba_train = pipe1.predict_proba(X0_train)\n",
    "Y_proba_test = pipe1.predict_proba(X0_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy_score_train': 0.5591356680505869,\n",
       " 'accuracy_score_test': 0.5607561617611869,\n",
       " 'cohen_kappa_train': 0.0,\n",
       " 'cohen_kappa_test': 0.0,\n",
       " 'log_loss_train': 0.6828891549341145,\n",
       " 'log_loss_test': 0.6823838947402037,\n",
       " 'f1_score_train': 0.0,\n",
       " 'f1_score_test': 0.0}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = {\n",
    "    'accuracy_score_train': accuracy_score(Y0_train, Y_pred_train),\n",
    "    'accuracy_score_test': accuracy_score(Y0_test, Y_pred_test),\n",
    "    'cohen_kappa_train': cohen_kappa_score(Y0_train, Y_pred_train),\n",
    "    'cohen_kappa_test': cohen_kappa_score(Y0_test, Y_pred_test),\n",
    "    'log_loss_train': log_loss(Y0_train, Y_poba_train),\n",
    "    'log_loss_test': log_loss(Y0_test, Y_proba_test),\n",
    "    'f1_score_train': f1_score(Y0_train, Y_pred_train),\n",
    "    'f1_score_test': f1_score(Y0_test, Y_pred_test)\n",
    "}\n",
    "res\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ The model does not show great performance, but the pipeline shows results. \n",
    "+ Below, we expand the pipeline to include more variables, and further we will work with more robust model selection pipelines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ColumnTransformer\n",
    "\n",
    "+ Use [`ColumnTransformer`](https://scikit-learn.org/stable/modules/generated/sklearn.compose.ColumnTransformer.html) to apply transformers to specific columns of a DataFrame.\n",
    "+ In this case, we will scale numeric variables and apply one-hot encoding to categorical columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-8 {color: black;background-color: white;}#sk-container-id-8 pre{padding: 0;}#sk-container-id-8 div.sk-toggleable {background-color: white;}#sk-container-id-8 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-8 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-8 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-8 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-8 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-8 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-8 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-8 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-8 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-8 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-8 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-8 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-8 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-8 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-8 div.sk-item {position: relative;z-index: 1;}#sk-container-id-8 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-8 div.sk-item::before, #sk-container-id-8 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-8 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-8 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-8 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-8 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-8 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-8 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-8 div.sk-label-container {text-align: center;}#sk-container-id-8 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-8 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-8\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;preproc&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;numeric_transfomer&#x27;,\n",
       "                                                  StandardScaler(),\n",
       "                                                  [&#x27;returns&#x27;, &#x27;Volume&#x27;, &#x27;op_cl&#x27;,\n",
       "                                                   &#x27;hi_lo&#x27;]),\n",
       "                                                 (&#x27;onehot&#x27;,\n",
       "                                                  OneHotEncoder(handle_unknown=&#x27;infrequent_if_exist&#x27;),\n",
       "                                                  [&#x27;Listing Exchange&#x27;,\n",
       "                                                   &#x27;Market Category&#x27;])])),\n",
       "                (&#x27;decisiontree&#x27;,\n",
       "                 DecisionTreeClassifier(criterion=&#x27;entropy&#x27;, max_depth=3))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" ><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;preproc&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;numeric_transfomer&#x27;,\n",
       "                                                  StandardScaler(),\n",
       "                                                  [&#x27;returns&#x27;, &#x27;Volume&#x27;, &#x27;op_cl&#x27;,\n",
       "                                                   &#x27;hi_lo&#x27;]),\n",
       "                                                 (&#x27;onehot&#x27;,\n",
       "                                                  OneHotEncoder(handle_unknown=&#x27;infrequent_if_exist&#x27;),\n",
       "                                                  [&#x27;Listing Exchange&#x27;,\n",
       "                                                   &#x27;Market Category&#x27;])])),\n",
       "                (&#x27;decisiontree&#x27;,\n",
       "                 DecisionTreeClassifier(criterion=&#x27;entropy&#x27;, max_depth=3))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-17\" type=\"checkbox\" ><label for=\"sk-estimator-id-17\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">preproc: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(transformers=[(&#x27;numeric_transfomer&#x27;, StandardScaler(),\n",
       "                                 [&#x27;returns&#x27;, &#x27;Volume&#x27;, &#x27;op_cl&#x27;, &#x27;hi_lo&#x27;]),\n",
       "                                (&#x27;onehot&#x27;,\n",
       "                                 OneHotEncoder(handle_unknown=&#x27;infrequent_if_exist&#x27;),\n",
       "                                 [&#x27;Listing Exchange&#x27;, &#x27;Market Category&#x27;])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-18\" type=\"checkbox\" ><label for=\"sk-estimator-id-18\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">numeric_transfomer</label><div class=\"sk-toggleable__content\"><pre>[&#x27;returns&#x27;, &#x27;Volume&#x27;, &#x27;op_cl&#x27;, &#x27;hi_lo&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-19\" type=\"checkbox\" ><label for=\"sk-estimator-id-19\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-20\" type=\"checkbox\" ><label for=\"sk-estimator-id-20\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">onehot</label><div class=\"sk-toggleable__content\"><pre>[&#x27;Listing Exchange&#x27;, &#x27;Market Category&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-21\" type=\"checkbox\" ><label for=\"sk-estimator-id-21\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(handle_unknown=&#x27;infrequent_if_exist&#x27;)</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-22\" type=\"checkbox\" ><label for=\"sk-estimator-id-22\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(criterion=&#x27;entropy&#x27;, max_depth=3)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('preproc',\n",
       "                 ColumnTransformer(transformers=[('numeric_transfomer',\n",
       "                                                  StandardScaler(),\n",
       "                                                  ['returns', 'Volume', 'op_cl',\n",
       "                                                   'hi_lo']),\n",
       "                                                 ('onehot',\n",
       "                                                  OneHotEncoder(handle_unknown='infrequent_if_exist'),\n",
       "                                                  ['Listing Exchange',\n",
       "                                                   'Market Category'])])),\n",
       "                ('decisiontree',\n",
       "                 DecisionTreeClassifier(criterion='entropy', max_depth=3))])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('numeric_transfomer', StandardScaler(), ['returns', 'Volume', 'op_cl', 'hi_lo'] ),\n",
    "        ('onehot', OneHotEncoder(handle_unknown='infrequent_if_exist'), ['Listing Exchange', 'Market Category']), \n",
    "    ], remainder='drop'\n",
    ")\n",
    "\n",
    "pipe = Pipeline(\n",
    "    [\n",
    "        ('preproc', transformer), \n",
    "        ('decisiontree', DecisionTreeClassifier(criterion = 'entropy', max_depth=3))\n",
    "    ]\n",
    ")\n",
    "pipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Selection\n",
    "\n",
    "The model selection process is an iterative process in which :\n",
    "\n",
    "+ Select schema and load data.\n",
    "+ Define a pipeline and its (hyper) parameters.\n",
    "\n",
    "    - Use ColumnTransformers to transform numeric and cateogrical variables.\n",
    "    - Hyperparameters can be defined independently of code. \n",
    "\n",
    "+ Implement a splitting strategy. \n",
    "\n",
    "    - Use [cross_validate]() to select several metrics and operational details.\n",
    "\n",
    "+ Measure performance.\n",
    "\n",
    "    - [Select metrics](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics)\n",
    "\n",
    "+ Repeat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training, Validation, Testing Split\n",
    "\n",
    "+ The first spliting strategy is to use a training, validation, and test set.\n",
    "+ Training set will be used to fit the model.\n",
    "+ Validation set is used to evaluate hyperparameter choice.\n",
    "+ Testing set is used to evaluate performance on data the model has not yet seen.\n",
    "+ In this case we want to compare two models: \n",
    "\n",
    "    - Decision Tree with 3 minumum samples per leaf.\n",
    "    - Decision Tree with 10 minimum samples per leaf.\n",
    "\n",
    "![](./images/03b_train_validate_test.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting parameters in pipeline steps\n",
    "\n",
    "+ One can obtain the parameters of a pipeline with `pipe.get_params()`.\n",
    "+ We can set any parameter of a pipeline with `pipe.set_parames(**kwargs)`. \n",
    "+ The input `**kwargs` is a dictionary of the params to be modified. Params of the steps are labeled with the name of the step followed by `__` and the name of the parameter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ There are a few steps that we will repeat: \n",
    "\n",
    "    - Fit the candidate model on training data.\n",
    "    - Predict on training and test data.\n",
    "    - Compute training and test performance metrics.\n",
    "    - Return.\n",
    "\n",
    "+ We encapsulate this procedure in a function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(clf, X_train, Y_train, X_test, Y_test):\n",
    "    clf.fit(X_train, Y_train)\n",
    "    Y_pred_train = clf.predict(X_train)\n",
    "    Y_pred_test = clf.predict(X_test)\n",
    "    Y_proba_train = clf.predict_proba(X_train)\n",
    "    Y_proba_test = clf.predict_proba(X_test)\n",
    "    performance_metrics = {\n",
    "        'log_loss_train': log_loss(Y_train, Y_proba_train),\n",
    "        'log_loss_test': log_loss(Y_test, Y_proba_test),\n",
    "        'cohen_kappa_train': cohen_kappa_score(Y_train, Y_pred_train),\n",
    "        'cohen_kappa_test': cohen_kappa_score(Y_test, Y_pred_test),\n",
    "        'f1_score_train': f1_score(Y_train, Y_pred_train),\n",
    "        'f1_score_test': f1_score(Y_test, Y_pred_test),\n",
    "        'accuracy_score_train': accuracy_score(Y_train, Y_pred_train),\n",
    "        'accuracy_score_test': accuracy_score(Y_test, Y_pred_test),\n",
    "    }\n",
    "    return performance_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Schema\n",
    "X = df[['returns', 'op_cl', 'hi_lo', 'Volume', 'Listing Exchange', 'Market Category']]\n",
    "Y = df['target']\n",
    "\n",
    "# Split the data\n",
    "X_rest, X_test, Y_rest, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "X_train, X_validate, Y_train,  Y_validate = train_test_split(X_rest, Y_rest, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'log_loss_train': 0.6718773489078965,\n",
       " 'log_loss_test': 0.6709691728203926,\n",
       " 'cohen_kappa_train': 0.0017509626884367746,\n",
       " 'cohen_kappa_test': 0.002312878605218338,\n",
       " 'f1_score_train': 0.004519189693549475,\n",
       " 'f1_score_test': 0.005286905792807985,\n",
       " 'accuracy_score_train': 0.5585400994072457,\n",
       " 'accuracy_score_test': 0.5647882268485284}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate hyperparameter configuration 2\n",
    "pipe_d3 = pipe.set_params(**{'decisiontree__max_depth': 3})\n",
    "res_d3 = evaluate_model(pipe_d3, X_train, Y_train, X_validate, Y_validate)\n",
    "res_d3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'log_loss_train': 0.6225527090157216,\n",
       " 'log_loss_test': 1.5570169280579707,\n",
       " 'cohen_kappa_train': 0.1866279596858953,\n",
       " 'cohen_kappa_test': 0.0918652667901887,\n",
       " 'f1_score_train': 0.5396517375803054,\n",
       " 'f1_score_test': 0.48573596009287145,\n",
       " 'accuracy_score_train': 0.6002622277393077,\n",
       " 'accuracy_score_test': 0.5539004546542236}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate hyperparameter configuration 2\n",
    "pipe_d15 = pipe.set_params(**{'decisiontree__max_depth':15})\n",
    "res_d15 = evaluate_model(pipe_d15, X_train, Y_train, X_validate, Y_validate)\n",
    "res_d15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-Validation\n",
    "\n",
    "+ Cross-validation is a resampling method.\n",
    "+ It is an iterative method applied to training data.\n",
    "+ Training data is divided into folds.\n",
    "+ Each fold is used once as a validation set and the rest of the folds are used for training.\n",
    "+ Test data is used for final evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From [Scikit's Documentation ](https://scikit-learn.org/stable/modules/cross_validation.html#cross-validation-evaluating-estimator-performance), the diagram below shows the data divisions and folds during the cross-validation process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./images/03b_grid_search_cross_validation.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two functions that can be used for [calculating cross-validation performance scores](https://scikit-learn.org/stable/modules/cross_validation.html#cross-validation-evaluating-estimator-performance): `cross_val_score()` and `cross_validate()`. The first function, [`cross_val_score()`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html#sklearn.model_selection.cross_val_score), is a convenience function to get quick perfromance calculations. We will discuss `cross_validate()` as it offers advantages over `cross_val_score()`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtaining metrics\n",
    "\n",
    "+ Use [`cross_validate`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_validate.html#sklearn.model_selection.cross_validate) to measure one or more performance metrics and operational details.\n",
    "+ There are two advantages of using this function. From [Scikit's documentation](https://scikit-learn.org/stable/modules/cross_validation.html#the-cross-validate-function-and-multiple-metric-evaluation):\n",
    "\n",
    ">- It allows specifying multiple metrics for evaluation.\n",
    ">- It returns a dict containing fit-times, score-times (and optionally training scores, fitted estimators, train-test split indices) in addition to the test score.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "scoring = ['accuracy', 'f1', 'precision', 'recall', 'roc_auc', 'neg_log_loss', 'neg_brier_score']\n",
    "d3_dict = cross_validate(pipe_d3, X, Y, cv=5, scoring = scoring, return_train_score = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([1.4459579 , 1.57808113, 1.43669987, 1.43854594, 1.49094772]),\n",
       " 'score_time': array([0.15771389, 0.16249299, 0.16562414, 0.15384316, 0.16037917]),\n",
       " 'test_accuracy': array([0.54009731, 0.55234905, 0.51805883, 0.55674494, 0.54718908]),\n",
       " 'train_accuracy': array([0.59600298, 0.59610668, 0.61011494, 0.59602454, 0.59665069]),\n",
       " 'test_f1': array([0.44522275, 0.37903029, 0.41937344, 0.26994929, 0.30919003]),\n",
       " 'train_f1': array([0.48859787, 0.49094958, 0.52559604, 0.41843027, 0.38835433]),\n",
       " 'test_precision': array([0.47507187, 0.4873108 , 0.44685644, 0.49186136, 0.47146144]),\n",
       " 'train_precision': array([0.55229008, 0.5519264 , 0.56642296, 0.57195103, 0.58494416]),\n",
       " 'test_recall': array([0.41890277, 0.31012131, 0.39507514, 0.18602209, 0.23001992]),\n",
       " 'train_recall': array([0.43807713, 0.44210574, 0.49025892, 0.32988412, 0.2906663 ]),\n",
       " 'test_roc_auc': array([0.54427253, 0.56380843, 0.52300922, 0.56192543, 0.56062354]),\n",
       " 'train_roc_auc': array([0.64850952, 0.64849967, 0.66858894, 0.64648798, 0.64989286]),\n",
       " 'test_neg_log_loss': array([-3.31353799, -1.51283725, -1.92185068, -2.28026979, -1.86727676]),\n",
       " 'train_neg_log_loss': array([-0.62813243, -0.62680898, -0.61780917, -0.62972898, -0.62592113]),\n",
       " 'test_neg_brier_score': array([-0.28440346, -0.25582767, -0.27058193, -0.26538971, -0.25843544]),\n",
       " 'train_neg_brier_score': array([-0.22309599, -0.22285967, -0.21894282, -0.22389763, -0.22245038])}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d3_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In DataFrame form:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>train_f1</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>train_precision</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>train_recall</th>\n",
       "      <th>test_roc_auc</th>\n",
       "      <th>train_roc_auc</th>\n",
       "      <th>test_neg_log_loss</th>\n",
       "      <th>train_neg_log_loss</th>\n",
       "      <th>test_neg_brier_score</th>\n",
       "      <th>train_neg_brier_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.445958</td>\n",
       "      <td>0.157714</td>\n",
       "      <td>0.540097</td>\n",
       "      <td>0.596003</td>\n",
       "      <td>0.445223</td>\n",
       "      <td>0.488598</td>\n",
       "      <td>0.475072</td>\n",
       "      <td>0.552290</td>\n",
       "      <td>0.418903</td>\n",
       "      <td>0.438077</td>\n",
       "      <td>0.544273</td>\n",
       "      <td>0.648510</td>\n",
       "      <td>-3.313538</td>\n",
       "      <td>-0.628132</td>\n",
       "      <td>-0.284403</td>\n",
       "      <td>-0.223096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.578081</td>\n",
       "      <td>0.162493</td>\n",
       "      <td>0.552349</td>\n",
       "      <td>0.596107</td>\n",
       "      <td>0.379030</td>\n",
       "      <td>0.490950</td>\n",
       "      <td>0.487311</td>\n",
       "      <td>0.551926</td>\n",
       "      <td>0.310121</td>\n",
       "      <td>0.442106</td>\n",
       "      <td>0.563808</td>\n",
       "      <td>0.648500</td>\n",
       "      <td>-1.512837</td>\n",
       "      <td>-0.626809</td>\n",
       "      <td>-0.255828</td>\n",
       "      <td>-0.222860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.436700</td>\n",
       "      <td>0.165624</td>\n",
       "      <td>0.518059</td>\n",
       "      <td>0.610115</td>\n",
       "      <td>0.419373</td>\n",
       "      <td>0.525596</td>\n",
       "      <td>0.446856</td>\n",
       "      <td>0.566423</td>\n",
       "      <td>0.395075</td>\n",
       "      <td>0.490259</td>\n",
       "      <td>0.523009</td>\n",
       "      <td>0.668589</td>\n",
       "      <td>-1.921851</td>\n",
       "      <td>-0.617809</td>\n",
       "      <td>-0.270582</td>\n",
       "      <td>-0.218943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.438546</td>\n",
       "      <td>0.153843</td>\n",
       "      <td>0.556745</td>\n",
       "      <td>0.596025</td>\n",
       "      <td>0.269949</td>\n",
       "      <td>0.418430</td>\n",
       "      <td>0.491861</td>\n",
       "      <td>0.571951</td>\n",
       "      <td>0.186022</td>\n",
       "      <td>0.329884</td>\n",
       "      <td>0.561925</td>\n",
       "      <td>0.646488</td>\n",
       "      <td>-2.280270</td>\n",
       "      <td>-0.629729</td>\n",
       "      <td>-0.265390</td>\n",
       "      <td>-0.223898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.490948</td>\n",
       "      <td>0.160379</td>\n",
       "      <td>0.547189</td>\n",
       "      <td>0.596651</td>\n",
       "      <td>0.309190</td>\n",
       "      <td>0.388354</td>\n",
       "      <td>0.471461</td>\n",
       "      <td>0.584944</td>\n",
       "      <td>0.230020</td>\n",
       "      <td>0.290666</td>\n",
       "      <td>0.560624</td>\n",
       "      <td>0.649893</td>\n",
       "      <td>-1.867277</td>\n",
       "      <td>-0.625921</td>\n",
       "      <td>-0.258435</td>\n",
       "      <td>-0.222450</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fit_time  score_time  test_accuracy  train_accuracy   test_f1  train_f1  \\\n",
       "0  1.445958    0.157714       0.540097        0.596003  0.445223  0.488598   \n",
       "1  1.578081    0.162493       0.552349        0.596107  0.379030  0.490950   \n",
       "2  1.436700    0.165624       0.518059        0.610115  0.419373  0.525596   \n",
       "3  1.438546    0.153843       0.556745        0.596025  0.269949  0.418430   \n",
       "4  1.490948    0.160379       0.547189        0.596651  0.309190  0.388354   \n",
       "\n",
       "   test_precision  train_precision  test_recall  train_recall  test_roc_auc  \\\n",
       "0        0.475072         0.552290     0.418903      0.438077      0.544273   \n",
       "1        0.487311         0.551926     0.310121      0.442106      0.563808   \n",
       "2        0.446856         0.566423     0.395075      0.490259      0.523009   \n",
       "3        0.491861         0.571951     0.186022      0.329884      0.561925   \n",
       "4        0.471461         0.584944     0.230020      0.290666      0.560624   \n",
       "\n",
       "   train_roc_auc  test_neg_log_loss  train_neg_log_loss  test_neg_brier_score  \\\n",
       "0       0.648510          -3.313538           -0.628132             -0.284403   \n",
       "1       0.648500          -1.512837           -0.626809             -0.255828   \n",
       "2       0.668589          -1.921851           -0.617809             -0.270582   \n",
       "3       0.646488          -2.280270           -0.629729             -0.265390   \n",
       "4       0.649893          -1.867277           -0.625921             -0.258435   \n",
       "\n",
       "   train_neg_brier_score  \n",
       "0              -0.223096  \n",
       "1              -0.222860  \n",
       "2              -0.218943  \n",
       "3              -0.223898  \n",
       "4              -0.222450  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(d3_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>train_f1</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>train_precision</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>train_recall</th>\n",
       "      <th>test_roc_auc</th>\n",
       "      <th>train_roc_auc</th>\n",
       "      <th>test_neg_log_loss</th>\n",
       "      <th>train_neg_log_loss</th>\n",
       "      <th>test_neg_brier_score</th>\n",
       "      <th>train_neg_brier_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.435112</td>\n",
       "      <td>0.156952</td>\n",
       "      <td>0.540624</td>\n",
       "      <td>0.595931</td>\n",
       "      <td>0.445399</td>\n",
       "      <td>0.488223</td>\n",
       "      <td>0.475707</td>\n",
       "      <td>0.552253</td>\n",
       "      <td>0.418722</td>\n",
       "      <td>0.437498</td>\n",
       "      <td>0.545479</td>\n",
       "      <td>0.648408</td>\n",
       "      <td>-3.325886</td>\n",
       "      <td>-0.628173</td>\n",
       "      <td>-0.284105</td>\n",
       "      <td>-0.223108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.576792</td>\n",
       "      <td>0.159760</td>\n",
       "      <td>0.552190</td>\n",
       "      <td>0.596051</td>\n",
       "      <td>0.378672</td>\n",
       "      <td>0.490767</td>\n",
       "      <td>0.487019</td>\n",
       "      <td>0.551873</td>\n",
       "      <td>0.309759</td>\n",
       "      <td>0.441843</td>\n",
       "      <td>0.563686</td>\n",
       "      <td>0.648281</td>\n",
       "      <td>-1.499665</td>\n",
       "      <td>-0.626962</td>\n",
       "      <td>-0.255675</td>\n",
       "      <td>-0.222924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.447881</td>\n",
       "      <td>0.163240</td>\n",
       "      <td>0.518075</td>\n",
       "      <td>0.610135</td>\n",
       "      <td>0.420584</td>\n",
       "      <td>0.526046</td>\n",
       "      <td>0.447109</td>\n",
       "      <td>0.566321</td>\n",
       "      <td>0.397031</td>\n",
       "      <td>0.491119</td>\n",
       "      <td>0.523068</td>\n",
       "      <td>0.668659</td>\n",
       "      <td>-1.946465</td>\n",
       "      <td>-0.617791</td>\n",
       "      <td>-0.270846</td>\n",
       "      <td>-0.218934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.442396</td>\n",
       "      <td>0.159723</td>\n",
       "      <td>0.556713</td>\n",
       "      <td>0.595993</td>\n",
       "      <td>0.269666</td>\n",
       "      <td>0.418511</td>\n",
       "      <td>0.491756</td>\n",
       "      <td>0.571845</td>\n",
       "      <td>0.185769</td>\n",
       "      <td>0.330020</td>\n",
       "      <td>0.561940</td>\n",
       "      <td>0.646470</td>\n",
       "      <td>-2.287861</td>\n",
       "      <td>-0.629673</td>\n",
       "      <td>-0.265437</td>\n",
       "      <td>-0.223888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.492636</td>\n",
       "      <td>0.157827</td>\n",
       "      <td>0.546742</td>\n",
       "      <td>0.596455</td>\n",
       "      <td>0.308003</td>\n",
       "      <td>0.389583</td>\n",
       "      <td>0.470356</td>\n",
       "      <td>0.583867</td>\n",
       "      <td>0.228970</td>\n",
       "      <td>0.292314</td>\n",
       "      <td>0.559858</td>\n",
       "      <td>0.649612</td>\n",
       "      <td>-1.871807</td>\n",
       "      <td>-0.626130</td>\n",
       "      <td>-0.258719</td>\n",
       "      <td>-0.222534</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fit_time  score_time  test_accuracy  train_accuracy   test_f1  train_f1  \\\n",
       "0  1.435112    0.156952       0.540624        0.595931  0.445399  0.488223   \n",
       "1  1.576792    0.159760       0.552190        0.596051  0.378672  0.490767   \n",
       "2  1.447881    0.163240       0.518075        0.610135  0.420584  0.526046   \n",
       "3  1.442396    0.159723       0.556713        0.595993  0.269666  0.418511   \n",
       "4  1.492636    0.157827       0.546742        0.596455  0.308003  0.389583   \n",
       "\n",
       "   test_precision  train_precision  test_recall  train_recall  test_roc_auc  \\\n",
       "0        0.475707         0.552253     0.418722      0.437498      0.545479   \n",
       "1        0.487019         0.551873     0.309759      0.441843      0.563686   \n",
       "2        0.447109         0.566321     0.397031      0.491119      0.523068   \n",
       "3        0.491756         0.571845     0.185769      0.330020      0.561940   \n",
       "4        0.470356         0.583867     0.228970      0.292314      0.559858   \n",
       "\n",
       "   train_roc_auc  test_neg_log_loss  train_neg_log_loss  test_neg_brier_score  \\\n",
       "0       0.648408          -3.325886           -0.628173             -0.284105   \n",
       "1       0.648281          -1.499665           -0.626962             -0.255675   \n",
       "2       0.668659          -1.946465           -0.617791             -0.270846   \n",
       "3       0.646470          -2.287861           -0.629673             -0.265437   \n",
       "4       0.649612          -1.871807           -0.626130             -0.258719   \n",
       "\n",
       "   train_neg_brier_score  \n",
       "0              -0.223108  \n",
       "1              -0.222924  \n",
       "2              -0.218934  \n",
       "3              -0.223888  \n",
       "4              -0.222534  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d15_dict = cross_validate(pipe_d15, X, Y, cv=5, scoring = scoring, return_train_score = True)\n",
    "pd.DataFrame(d15_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# About Performance\n",
    "\n",
    "+ Notice that in order to acquire information about our model and continue development, we are spending resources: time, electricity, equipment use, etc. As well, we are generating data and binary objects that implement our models (fitted `Pipeline` objects, for example).\n",
    "+ For certain applications, operating performance (latency or `'score_time'`) may be as important or more important than predictive performance metrics. \n",
    "+ Every experiment throws important information and we can log them, as well as run them systematically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fit_time                 1.478963\n",
       "score_time               0.159500\n",
       "test_accuracy            0.542869\n",
       "train_accuracy           0.598913\n",
       "test_f1                  0.364465\n",
       "train_f1                 0.462626\n",
       "test_precision           0.474389\n",
       "train_precision          0.565232\n",
       "test_recall              0.308050\n",
       "train_recall             0.398559\n",
       "test_roc_auc             0.550806\n",
       "train_roc_auc            0.652286\n",
       "test_neg_log_loss       -2.186337\n",
       "train_neg_log_loss      -0.625746\n",
       "test_neg_brier_score    -0.266957\n",
       "train_neg_brier_score   -0.222278\n",
       "dtype: float64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(d15_dict).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fit_time                 1.478047\n",
       "score_time               0.160011\n",
       "test_accuracy            0.542888\n",
       "train_accuracy           0.598980\n",
       "test_f1                  0.364553\n",
       "train_f1                 0.462386\n",
       "test_precision           0.474512\n",
       "train_precision          0.565507\n",
       "test_recall              0.308028\n",
       "train_recall             0.398198\n",
       "test_roc_auc             0.550728\n",
       "train_roc_auc            0.652396\n",
       "test_neg_log_loss       -2.179154\n",
       "train_neg_log_loss      -0.625680\n",
       "test_neg_brier_score    -0.266928\n",
       "train_neg_brier_score   -0.222249\n",
       "dtype: float64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(d3_dict).mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsi_participant",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
